FFMPEG Documentation
       ffmpeg is a very fast video and audio converter that can also 
       grab from a live audio/video source. It can also convert between 
       arbitrary sample rates and resize video on the fly with a high 
       quality polyphase filter.

       ffmpeg reads from an arbitrary number of input "files" (which 
       can be regular files, pipes, network streams, grabbing devices, 
       etc.), specified by the "-i" option, and writes to an arbitrary 
       number of output "files", which are specified by a plain output
       url. Anything found on the command line which cannot be inter-
       preted as an option is considered to be an output url.

       Each input or output url can, in principle, contain any number of 
       streams of different types (video/audio/subtitle/attachment/data). 
       The allowed number and/or types of streams may be limited by the 
       container format. Selecting which streams from which inputs will 
       go into which output is either done automatically or with the 
       "-map" option (see the Stream selection chapter).

       To refer to input files in options, you must use their indices 
       (0-based). E.g.  the first input file is 0, the second is 1, etc. 
       Similarly, streams within a file are referred to by their indices. 
       E.g. "2:3" refers to the fourth stream in the third input file. 
       Also see the Stream specifiers chapter.

       As a general rule, options are applied to the next specified file. 
       Therefore, order is important, and you can have the same option on 
       the command line multiple times. Each occurrence is then applied 
       to the next input or output file.  Exceptions from this rule are 
       the global options (e.g. verbosity level), which should be specified 
       first.

       Do not mix input and output files -- first specify all input files, 
       then all output files. Also do not mix options which belong to 
       different files. All options apply ONLY to the next input or output 
       file and are reset between files.

       •   To set the video bitrate of the output file to 64 kbit/s:

		   ffmpeg -i input.avi -b:v 64k -bufsize 64k output.avi

       •   To force the frame rate of the output file to 24 fps:

		   ffmpeg -i input.avi -r 24 output.avi

       •   To force the frame rate of the input file (valid for raw formats only) to 1 fps and the frame
	   rate of the output file to 24 fps:

		   ffmpeg -r 1 -i input.m2v -r 24 output.avi

       The format option may be needed for raw input files.

DETAILED DESCRIPTION
       The transcoding process in ffmpeg for each output can be described by the following diagram:

		_______ 	     ______________
	       |       |	    |		   |
	       | input |  demuxer   | encoded data |   decoder
	       | file  | ---------> | packets	   | -----+
	       |_______|	    |______________|	  |
							  v
						      _________
						     |	       |
						     | decoded |
						     | frames  |
						     |_________|
		________	     ______________	  |
	       |	|	    |		   |	  |
	       | output | <-------- | encoded data | <----+
	       | file	|   muxer   | packets	   |   encoder
	       |________|	    |______________|

       ffmpeg calls the libavformat library (containing demuxers) to read input files and get packets
       containing encoded data from them. When there are multiple input files, ffmpeg tries to keep them
       synchronized by tracking lowest timestamp on any active input stream.

       Encoded packets are then passed to the decoder (unless streamcopy is selected for the stream, see
       further for a description). The decoder produces uncompressed frames (raw video/PCM audio/...)
       which can be processed further by filtering (see next section). After filtering, the frames are
       passed to the encoder, which encodes them and outputs encoded packets. Finally those are passed to
       the muxer, which writes the encoded packets to the output file.

   Filtering
       Before encoding, ffmpeg can process raw audio and video frames using filters from the libavfilter
       library. Several chained filters form a filter graph. ffmpeg distinguishes between two types of
       filtergraphs: simple and complex.

       Simple filtergraphs

       Simple filtergraphs are those that have exactly one input and output, both of the same type. In
       the above diagram they can be represented by simply inserting an additional step between decoding
       and encoding:

		_________			 ______________
	       |	 |			|	       |
	       | decoded |			| encoded data |
	       | frames  |\		      _ | packets      |
	       |_________| \		      /||______________|
			    \	__________   /
		 simple     _\||	  | /  encoder
		 filtergraph   | filtered |/
			       | frames   |
			       |__________|

       Simple filtergraphs are configured with the per-stream -filter option (with -vf and -af aliases
       for video and audio respectively).  A simple filtergraph for video can look for example like this:

		_______        _____________	    _______	   ________
	       |       |      | 	    |	   |	   |	  |	   |
	       | input | ---> | deinterlace | ---> | scale | ---> | output |
	       |_______|      |_____________|	   |_______|	  |________|

       Note that some filters change frame properties but not frame contents. E.g. the "fps" filter in
       the example above changes number of frames, but does not touch the frame contents. Another example
       is the "setpts" filter, which only sets timestamps and otherwise passes the frames unchanged.

       Complex filtergraphs

       Complex filtergraphs are those which cannot be described as simply a linear processing chain
       applied to one stream. This is the